{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWClckaQ5Wrb"
   },
   "source": [
    "## Lab 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJ_8N_zm5Wrd"
   },
   "source": [
    "### Part 2. Almost Shakespeare (2.0 points)\n",
    "\n",
    "В этой части задания мы научимся генерировать текст с помощью нейронных сетей. Конкретнее, обучим нейронную сеть на сонетах Шекспира и попросим нейросеть написать свой сонет.\n",
    "\n",
    "Генерация текста обычно включает в себя следующие шаги:\n",
    "    \n",
    "1. Загрузка данных.\n",
    "2. Создание словарей слов/символов.\n",
    "3. Препроцессинг данных.\n",
    "4. Обучение модели (нейросети).\n",
    "5. Генерация нового текста.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEmxwXPg5Wrf"
   },
   "source": [
    "#### Часть 1. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ZVZcieV5Wri"
   },
   "source": [
    "Для начала загрузим данные. Файл с сонетами Шекспира доступен по [ссылке](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). Кроме того, он находится рядом с этим ноутбуком (`sonnetes.txt`).\n",
    "\n",
    "Базовая предобработка уже сделана: текст состоит непосредственно из поэм Шекспира и названий/номеров глав, все техническая информация удалена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59p9qo7m5Wrk"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKgbKoG15Wrt"
   },
   "outputs": [],
   "source": [
    "with open('sonnets.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START:TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HigFNLt25Wr0"
   },
   "source": [
    "Так как в этот раз мы хотим научиться предсказывать текст, понизим сложность задачи и приведем текст к нижнему регистру.\n",
    "\n",
    "В настоящий момент переменная `text` представляет собой список из строк. Объедините все строки в одну и приведите к нижнему регистру. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AO9zFhFHEvd9"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2QIRB-85Wr1"
   },
   "outputs": [],
   "source": [
    "text = ''.join(text).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6EutkGoD5Wr7",
    "outputId": "f0973152-7804-4276-a6ac-79a7fc841c78"
   },
   "outputs": [],
   "source": [
    "# Объедините все строки в одну и приведите к нижнему регистру.\n",
    "# Результат запишите в переменную text.\n",
    "\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('Отлично!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRO1vAFH5WsD"
   },
   "source": [
    "Выделите множество всех символов, с которыми нам довелось встретиться в переменную `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EOI8wPQl5WsE"
   },
   "outputs": [],
   "source": [
    "tokens = sorted(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZuWRHLmA5WsK"
   },
   "source": [
    "Постройте словарь `token_to_idx` вида <символ>: <индекс> и словарь `idx_to_token` вида <индекс>: <символ>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ti22WeMx5WsM"
   },
   "outputs": [],
   "source": [
    "# словарь вида <индекс>:<символ>\n",
    "token_to_idx = {tkn: i for i, tkn in enumerate(tokens)}\n",
    "\n",
    "# словарь вида <символ>:<индекс>\n",
    "idx_to_token = {i: tkn for i, tkn in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KW2hGnUQ5WsS"
   },
   "source": [
    "*Комментарий: т.к. у нас всего 38 различных токенов, в этот раз воспользуемся one-hot encoding'ом.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsGU5-8y5WsT"
   },
   "source": [
    "## Построение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7CUgTIG5WsU"
   },
   "source": [
    "Теперь наша задача - создать и обучить рекуррентную нейронную сеть, которая сможет генерировать что-то похожее на поэзию Шекспира.\n",
    "\n",
    "Для начала воспользуемся классической RNN, аналогичной построенной на семинаре. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9r3RI5U5WsV"
   },
   "source": [
    "## RNN\n",
    "<br/>\n",
    "Скрытый элемент\n",
    "$$ h_t= tanh⁡ (W_{ℎℎ} h_{t−1}+W_{xh} x_t) $$\n",
    "Выход сети\n",
    "\n",
    "$$ y_t = W_{hy} h_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7dMQCOn5WsW"
   },
   "source": [
    "![1sa](data/rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4PAs7Z_5WsX"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_tokens=len(token_to_idx), embedding_size=100, rnn_num_units=200):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        self.activation = nn.PReLU(num_parameters=self.num_units)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "\n",
    "        x_emb = self.embedding(x)\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=-1)\n",
    "        h_next = self.rnn_update(x_and_h)\n",
    "        \n",
    "        h_next = self.activation(h_next)\n",
    "        logits = self.rnn_to_logits(h_next)\n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        return torch.randn(batch_size, self.num_units, requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5xP-ShX5Wse"
   },
   "outputs": [],
   "source": [
    "def to_matrix(tok_to_id, text, samples_num=5000, batch_len=300):\n",
    "    \n",
    "    return torch.tensor([[tok_to_id[tok] for tok in text[start:start+batch_len]]\n",
    "            for start in torch.randint(0, len(text) - batch_len, (samples_num,))]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nctl-0eQ5Wsi"
   },
   "outputs": [],
   "source": [
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NU7vCcz15Wsl"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "batch_size = 200\n",
    "model = RNN()\n",
    "dataloader = DataLoader(to_matrix(token_to_idx, text), batch_size=batch_size, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fKkSmF5q5Wso"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=100):\n",
    "    \n",
    "    since = time.time()\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs in dataloader:\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logp_seq = rnn_loop(model, inputs)\n",
    "            #predictions_logp = logp_seq[:, :-1]\n",
    "            #actual_next_tokens = inputs[:, 1:]\n",
    "\n",
    "            logp_next = torch.gather(logp_seq[:, :-1], dim=2, index=inputs[:, 1:][:,:,None])\n",
    "\n",
    "            loss = -logp_next.mean()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            running_loss += loss\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        losses.append(epoch_loss)\n",
    "        clear_output(True)\n",
    "        plt.plot(losses, label='current loss: {:.2}'.format(epoch_loss))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "colab_type": "code",
    "id": "Oa-rxc8u5Wst",
    "outputId": "fd70cb90-7b80-49fd-8e44-709ea0a5a388"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 10m 49s\n"
     ]
    }
   ],
   "source": [
    "model, losses = train_model(model, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgaBKlxr5Wsw"
   },
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase='hello my friends, ', max_length=500, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64, device=device)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    char_rnn.eval()\n",
    "    \n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.cpu().numpy()[0]\n",
    "        \n",
    "        next_ix = np.random.choice(len(token_to_idx), p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64, device=device)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.cpu().numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "049eP62C5Wsz",
    "outputId": "9dc7c3c2-fa77-4e2a-fbc2-2ef45a2f8e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello my friends, i want to say that the world may be be their his brand,\n",
      "  that they thou speedes thee my seem\n",
      "  but beauty's so such make,\n",
      "  and thee, determ\n",
      "  i have i nothing strange do more than he thoughts and doth lie,\n",
      "  which thy self worth the thoughts and seen the lies a self-loss of me to the stars of thee that beauty art,\n",
      "  and ablit is the storm and thee, when thee to his belong;\n",
      "  which thou art,\n",
      "  as those that wear thou that my love is all my love of that i no mand of my heart to\n"
     ]
    }
   ],
   "source": [
    "print(generate_sample(model, seed_phrase='hello my friends, i want to say that', max_length=500, temperature=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsejeGHA5Ws2"
   },
   "source": [
    "Постройте график функции потерь в зависимости от номера эпохи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4b2-mIoy5Ws3"
   },
   "source": [
    "### Более поэтичная модель\n",
    "\n",
    "Теперь давайте воспользуемся LSTM слоем вместо классической RNN и сравним результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQMfIW7w5Ws4"
   },
   "source": [
    "Снова постройте график функции потерь от числа эпох. Стал ли финальный loss лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yn1mfl425Ws4"
   },
   "source": [
    "\n",
    "# LSTM\n",
    "Скрытый элемент\n",
    "$$ c'_t= tanh⁡ (W_{xc} x_{t}+W_{hc} h_{t-1} + b_{c'}) $$\n",
    "$$ i_t = \\sigma (W_{xi} x_{t}+W_{hi} h_{t-1} + b_i) $$\n",
    "$$ f_t= \\sigma (W_{xf} x_{t}+W_{hf} h_{t-1} + b_f) $$\n",
    "$$ o_t= \\sigma (W_{xo} x_{t}+W_{ho} h_{t-1} + b_o) $$\n",
    "$$ c_t= f_t * c_{t-1} + i_t * c'_t $$\n",
    "$$ h_t= o_t * tanh (c_t) $$\n",
    "\n",
    "Выход сети\n",
    "\n",
    "$$ y_t = W_{hy} h_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQ3VXj6w5Ws5"
   },
   "source": [
    "![1](data/lstm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oV7IGQnA5Ws5"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_tokens=len(token_to_idx), embedding_size=100, rnn_num_units=200):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        \n",
    "        self.lstm = nn.LSTMCell(embedding_size, rnn_num_units)\n",
    "        self.fc = nn.Linear(in_features=rnn_num_units, out_features=len(token_to_idx))\n",
    "        \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        h, c = self.lstm(x_emb, (h_prev, c_prev))\n",
    "        \n",
    "        output = self.fc(h)\n",
    "        \n",
    "        return h, c, F.log_softmax(output, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        return torch.randn(batch_size, self.num_units, requires_grad=True).to(device), \\\n",
    "               torch.randn(batch_size, self.num_units, requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5ZJp3p15Ws8"
   },
   "outputs": [],
   "source": [
    "def lstm_loop(model, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state, cell_state = model.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0, 1):\n",
    "        hid_state, cell_state, logp_next = model(x_t, hid_state, cell_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TL9p-pJF5WtA"
   },
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "dataloader = DataLoader(to_matrix(token_to_idx, text), batch_size=batch_size, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-1, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUiLQzk25WtE"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=100):\n",
    "    \n",
    "    since = time.time()\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs in dataloader:\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logp_seq = lstm_loop(model, inputs)\n",
    "            predictions_logp = logp_seq[:, :-1]\n",
    "            actual_next_tokens = inputs[:, 1:]\n",
    "\n",
    "            logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
    "\n",
    "            loss = -logp_next.mean()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            running_loss += loss\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        losses.append(epoch_loss)\n",
    "        clear_output(True)\n",
    "        plt.plot(losses, label='current loss: {:.2}'.format(epoch_loss))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "PoXZdUvV5WtI",
    "outputId": "ed1440a4-d50a-46b4-9f7a-1bbd91603e4c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 10m 60s\n"
     ]
    }
   ],
   "source": [
    "model, losses = train_model(model, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_f_dICPV5WtL"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, init=' Hide my will', length=256, temperature=1.0):\n",
    "\n",
    "    x_sequence = [token_to_idx[token] for token in init]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64, device=device)\n",
    "    hid_state, cell_state = model.initial_state(batch_size=1)\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(len(init) - 1):\n",
    "        hid_state, cell_state, _ = model(x_sequence[:, i], hid_state, cell_state)\n",
    "    \n",
    "    for _ in range(length - len(init)):\n",
    "        hid_state, cell_state, logp_next = model(x_sequence[:, -1], hid_state, cell_state)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.cpu().numpy()[0]\n",
    "        \n",
    "        next_ix = np.random.choice(len(token_to_idx), p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64, device=device)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.cpu().numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated texts:\n",
      "please, go to the ground;\n",
      "  and for the peace of you i hold such strife\n",
      "  as 'twixt a miser and his \n",
      "--------------------\n",
      "please, go to the grown,\n",
      "  and by a gife, to borrow faith whs i compare thee to alone\n",
      "  the barn, to\n",
      "--------------------\n",
      "please, go to the grown,\n",
      "  and by thee in thee blood,\n",
      "  or made my som the still shall gloy,\n",
      "  in pr\n",
      "--------------------\n",
      "please, go to thy wisht bee lives monest be summer, not shall die-pays\n",
      "  is use rememberat by sumovi\n",
      "--------------------\n",
      "please, go to must ed?li-' fr,h\n",
      "  herlfoound phears, forb(n dowh:-'bri'd,\n",
      "  and not\n",
      "  thy peaiw'; mi\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated texts:\")\n",
    "\n",
    "for temp in [0.1, 0.2, 0.5, 1.0, 2.0]:\n",
    "    print(generate_text(model, init='please, go to ', length=100, temperature=temp))\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XT56s8Xo5WtU"
   },
   "source": [
    "Сгенерируйте текст с помощью обученной сети для различных значений параметра `temperature`: `[0.1, 0.2, 0.5, 1.0, 2.0]` (\"температуры\" при генерации). Оцените результаты визуально, попробуйте их проинтерпретировать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xySj0cYk5WtU"
   },
   "source": [
    "Здесь можно оставить свои рассуждения касательно интерпретации результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдения: чем больше temperature, тем хуже получается смысл, как я понимаю, вероятность занижмается сигмоидой. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DgVXJgA95WtV"
   },
   "source": [
    "#### Сохранение и загрузка модели\n",
    "\n",
    "Сохраните обученную модель на диск, затем загрузите ее и сгенерируйте текст. Примеры доступны по [ссылке](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LO6g_nGn5WtV"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM()\n",
    "lstm.load_state_dict(torch.load('model/lstm.pth'))\n",
    "lstm.to(device)\n",
    "\n",
    "print('generate text from loaded model:')\n",
    "print(generate_text(lstm, init='please, go to ', length=100, temperature=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89X0DJxV5WtX"
   },
   "source": [
    "Данная часть задания завершена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJcpAZj55WtX"
   },
   "source": [
    "#### Полезные ссылки\n",
    "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Статья Андрея Карпатого про RNN. </a> В качестве примеров рассматриваются задачи генерации Шекспировских текстов, Latex формул, Linux Source Code и детских имен.\n",
    "2. <a href='https://github.com/karpathy/char-rnn'> Репозиторий с кодом по char-rnn </a> (тоже за авторством Андрея Карпатого)\n",
    "3. Полезный репозиторий по PyTorch: [ссылка](https://github.com/spro/practical-pytorch`)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "Lab2_DL_part2-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
